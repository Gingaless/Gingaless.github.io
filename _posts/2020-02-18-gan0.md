---

title: "GAN(generative adversarial networks)"
date: 2020-02-18 13:51 -0
categories: ML
comments: true
published: false

---

이 보관용 글은 GAN이 처음 소개된 Ian Goodfellow의 논문과 본인의 머릿속 내용을 정리한 것이다.


GAN은 generative model(생성모델)이다.

생성모델은 모델이 생성하는 샘플의 분포를 실제 데이터의 분포에 최대한 근사하도록 만드는 것이 목적이다.

쉽게 말하면 걍 진짜 같은 짜가를 만드는 게 목적이다.

GAN은 adversarial process(적대적 프로세스)를 통해 자신을 최적화시키는 생성모델이다.

GAN을 개발한 이안 굿펠로우의 비유에 따라 적대적 프로세스를 설명하자면, 적대적 프로세스는 위조지폐 제조자와 경찰의 숨막히는 자강두천과 같다.

미숙한 위조지폐 제조자가 위조지폐를 등신 같이 만들다 경찰한테 걸리면, 경찰은 정신 좀 차리고 똑바로 살라고 위조지폐 제작자를 줘팬다.

그러면 위조지폐 제조자는 차리라는 정신은 안 차리고, 경찰의 줘팸에 영감을 받아 더 진짜 같은 위조지폐를 만든다.

하지만 경찰은 이미 위조지폐 제조자의 신원을 파악한 상태. 위조지폐 제조자가 제시하는 지폐는 모두 짜가라는 것을 아는 경찰은 제조자의 향상된 실력에 경악하며 다시 한번 제조자를 줘팬다.

그럼 제조자는 다시 심기일전하여 더 나은 위조지폐를 만든다.

경찰은 제조자가 만든 새 위조지폐를 보고 진짜인줄 알고 속을뻔하나, 전에 줘팼었던 그 놈인 걸 깨닫고 또 그를 줘팬다. 그리고 그가 만든 위조지폐에 속지 않기 위해 그가 만든 위조지폐의 특징을 파악하여 진짜 지폐와 구별할 수 있도록 학습한다.

그러나 경찰이 학습하는 동안, 위조지폐 제조자는 이미 더 나은 위조지폐를 만들어 경찰을 속이려고 하고 있었는데...!

하지만 경찰은 속지 않고, 위조지폐의 특징을 학습하고 구별해내며, 경찰에게 또 줘팸당한 위조지폐 제조자는 다시 더 진짜 같은 위조지폐를 만들기 위해 다시 연구를 시작한다.

뭐 대충 이런 순환 구조가 계속 반복되는 것이다.

GAN에서는 경찰 역할을 하는 모듈을 분별자(discriminator), 위조지페 제조자 역할을 하는 모듈을 생성자(generator)라고 한다.

경찰에게 쳐맞고 와신상담하며 최고의 위조지폐 장인을 꿈꾸는 위조지폐 꿈나무(?)처럼, Generator는 Discriminator의 면박을 받으면서 점점 진짜에 가까운 데이터나 샘플을 생성해간다.


[![GAN is awesome](http://img.youtube.com/vidCKbRCUyop8/0.jpg)](http://www.youtube.com/watch?v=dCKbRCUyop8)

위의 영상은 현재의 GAN이 얼마나 발전했는지 보여준다. 영상에 나오는 GAN이 생성해낸 이미지는 실제에 가까우며, GAN의 latent space를 돌아댕기며 자신이 원하는 이미지를 생성할 수 있다.

하지만 현재 기술이 얼마나 발전했든지간에 그것이 내가 만든 GAN의 수준을 보장해주진 않는다 시발^^.


참고로 GAN은 Imitation Learning이라는 RL(Reinforcement Learning) 알고리즘의 특수한 형태 중의 하나인데, 이 얘기는 기회가 되면 다른 게시물에서 하도록 하고.


앞에서 비유로 표현한 GAN의 학습 알고리즘을 구체적으로 설명하자면,

일단 생성자(generator) G가 z라는 확률변수(random variable)을 받아 가짜샘플을 만들어낸다.

앞의 비유에서는 위조지폐 제작자가 위조지페를 만드는 일과 동일하다.

그리고 분별자(discriminator) D는 입력값으로 현실에 존재하는 샘플과 생성자가 만들어낸 가짜 샘플을 받아, 그것이 얼마나 진짜 같은지를 0과 1 사이의 값으로 표현한다. 0에 가까울수록 가짜, 1에 가까울수록 진짜이다.

당연하게도 성능 좋은 분별자는 현실에 존재하는 샘플은 진짜 같다고(즉 출력값이 1에 가까워야) 해야 하고, 가짜 샘플은 가짜 같다고(즉 출력값이 0에 가깝) 해야 할 것이다.

응? 가짜만 잘 잡아내면 되지 않느냐고? 아니 진짜를 가짜라고 오판하지 않는 것도 중요하지. 위조지폐의 비유로 보면 가짜를 잘 잡아내기만 하는 경찰은 구소련 비밀경찰들, 중국 공안들과 다를 바가 없지 반동분자 1명 잡을라고 일반인 100명도 함께 감옥에 집어처넣는 수쥰;;;

우리는 민주 시민들이 이끄는 민주주의 국가 대한민국에서 살기 때문에 그런 습근평평이 같은 말 하면 쳐맞아요 아셨죠?

뭐 그래서 우리는 현실의 샘플을 입력받은 D는 1에 가까운 값을, 생성자가 만들어낸 가짜 샘플을 입력받은 D는 0에 가끼운 값을 출력하도록 분별자를 최적화해야 한다.

그런 방향으로 D를 최적화시키는 방식에는 여러가지가 있지만, 최초의 GAN에서는 크로스엔트로피를 최소화하여 D를 최적화시키고자 했다.


즉, $min _{D} H(p_{data}, D) + H(p_{g}, 1 - D), \text{$p_{data}$는 진짜 샘플들의 확률분포함수, $p_g$는 생성자가 만들어내는 가짜 샘플들의 확률분포함수.}$
이 조건을 만족시키는 D가 최적화된 분별자라는 것이다.

분별자 D의 출력값이 '샘플이 진짜일 확률'의 추정값이라면, $1 - D$는 '샘플이 진짜가 아닐, 즉 가짜일 확률'의 추정값일 것이다.

크로스엔트로피를 다룬 게시글에서 말했듯이, 크로스엔트로피는 두 확률분포가 같을 때 최소화된다.

따라서 위 조건을 만족하는 분별자는 진짜 샘플을 입력받으면 1을 출력하고, 생성자가 만들어낸 가짜 샘플을 입력받으면 0을 출력하는 이상적이고 모범적인 분별자일 것이다.

자, 그럼 이제 생성자에 대한 이야기를 해보자.

성능 좋은 생성자는 '진짜에 가까운' 가짜샘플을 만들어내는 생성자이다. 우수한 위조지폐 제작자는 진짜 같은 위조지폐를 만드는 사람인 것처럼 말이다.

따라서 생성자가 얼마나 성능이 좋은지 알아보려면 생성자가 만들어낸 가짜샘플이 얼마나 현실의 샘플과 닮았는지 정량할 필요가 있다.

그러면 어떻게 해야 가짜샘플이 얼마나 진짜 같은지 정량할 수 있을까? 사람이 대충 눈으로 보고 점수를 매기면 될까?

물론 안되지 이 사람아!

사람이 일일히 점수를 매기는 일은 매우 귀찮은 일이고, 또한 객관성 또한 떨어진다.

그럼 뭐 어쩌라는거임?

아아, 답은 '깜방 갈 각오를 하고 위조지폐범 잡는 경찰한테 가서 물어본다.'이다.

즉, 분별자에 가짜샘플을 입력하여 출력값이 1에 얼마나 가까운지를 보는 것이다.

최초의 GAN에서는 이를 정량하기 위해 또 크로스엔트로피를 사용했다.

즉, 최적화된 생성자는,

$\max _{G} H(p_g, 1 - D)$ 를 만족하는 생성자이다.

다시 말해, '샘플이 가짜일 확률'에 대한 추정값인 $1 - D$와의 크로스엔트로피를 최대화하여 '분별자가 추정한 가짜샘플의 확률분포가 가짜샘플들의 실제 확률분포에서 멀어지도록 하는' 생성자가 최적화된 생성자이다.

쉽게 말하자면 분별자가 가짜가 아닐 가능성이 높다고 판별하는 가짜샘플들을 많이 맹글어내야 좋은 생성자라는 것이다.

자, 그럼 이제 분별자와 생성자 둘다 동시에 고려해보자.

분별자는 실제 샘플들의 확률분포와 그에 대한 추정값 사이의 크로스엔트로피 + 거짓된 샘플들의 확률분포와 그에 대한 추정값 사이의 크로스엔트로피를 최소화해야 하고,

생성자는 거짓된 샘플들의 확률분포와 그에 대한 추정값 사이의 크로스 엔트로피를 최대화해야 한다.

한쪽에선 크로스엔트로피를 최소화해야 하고, 다른 쪽에선 크로스엔트로피를 최대화해야 한다.

크로스엔트로피가 최소화되면서 동시에 최대화될 수는 없는 노릇이니, 분별자와 생성자는 마치 줄다리기하는 것처럼 크로스 엔트로피 값을 자신을 최적화하는 방향으로 움직이기 위해 서로 싸워야 한다.

이것이 바로 분별자와 생성자 간의 minimax game, 최소최대화 문제라는 것이다!

이 최소최대화 문제를 해결하는 과정에서 생성자는 실제 샘플들의 확률 분포를 학습해나간다.

마치 범죄자를 잡으려는 경찰과 안 잡히려는 위조지폐범간의 숨막히는 자강두천 대결 속에서 두 사람이 서로 절차탁마해나간 끝에 위조지폐범이 전설의 위조지페범이 되는 것처럼...!

아니 시발 이게 뭔 잡소리지

어쨋든간에 지금까지가 GAN의 작동기작에 대한 개략적인 설명이었고, 다들 꽤나 그럴듯한 알고리즘이라고 생각할 것이다.

... 나만 그렇게 생각하나?

하지만 세상엔 엄근진한 태도로 GAN의 알고리즘에 대해 불경한 의구심을 품는 사람들도 있는 것이다...!

"그래, 직관적으론 말이 되는 알고리즘이야. 하지만 내 직관대로라면 느그아부지는 하늘에 계시거든?"

"이게 제대로 작동하는 알고리즘이 맞는지 수학적으로 증명하지 않으면 너희 아버지를 대기권 밖으로 날려보낼 것이다...!"

아니 이게 대체 무슨 패드립이야 이거.

그리하여 아버지에게 우주여행 패키지를 선물해드리고 싶지 않았던 GAN 논문의 저자 이안 굳펠로우는 GAN 알고리즘을 수학적으로 증명해냈는데, 좀 야매로 증명해놨다.

어떤 야매를 써서 증명했냐면, '분별자와 생성자의 구조는 모든 확률분포함수를 나타낼 수 있을 만큼 강력하다.'라고 가정하는 야매를 썼다.

이는 당연하게도 현실과는 동떨어진 이야기다.

예를 들어, 생성자를 정규분포함수로 설정했다면 아무리 파라미터를 조정한다 하더라도 생성자가 연속균등확률분포를 나타낼 수가 없다.


